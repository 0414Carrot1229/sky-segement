import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset, random_split
from torchvision import transforms
from PIL import Image
import os


# 定义 U-Net 网络架构
class UNet(nn.Module):
    def __init__(self, in_channels=3, out_channels=1):
        super(UNet, self).__init__()

        # 编码
        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)

        self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # 增加通道数
        self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)  # 增加通道数
        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)

        # 解码
        self.up1 = nn.ConvTranspose2d(256, 256, kernel_size=2, stride=2)  # 增加通道数
        self.conv7 = nn.Conv2d(512, 256, kernel_size=3, padding=1)  # 512 because we concatenate with the skip connection
        self.conv8 = nn.Conv2d(256, 256, kernel_size=3, padding=1)

        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.conv9 = nn.Conv2d(256, 128, kernel_size=3, padding=1)
        self.conv10 = nn.Conv2d(128, 128, kernel_size=3, padding=1)

        self.up3 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.conv11 = nn.Conv2d(128, 64, kernel_size=3, padding=1)
        self.conv12 = nn.Conv2d(64, 64, kernel_size=3, padding=1)

        self.conv13 = nn.Conv2d(64, out_channels, kernel_size=1)

    def forward(self, x):
        # 编码
        x1 = self.conv1(x)
        x1 = nn.ReLU()(x1)
        x1 = self.conv2(x1)
        x1 = nn.ReLU()(x1)
        x1_pool = self.pool1(x1)

        x2 = self.conv3(x1_pool)
        x2 = nn.ReLU()(x2)
        x2 = self.conv4(x2)
        x2 = nn.ReLU()(x2)
        x2_pool = self.pool2(x2)

        x3 = self.conv5(x2_pool)
        x3 = nn.ReLU()(x3)
        x3 = self.conv6(x3)
        x3 = nn.ReLU()(x3)
        x3_pool = self.pool3(x3)

        # 解码
        x4 = self.up1(x3_pool)
        x4 = torch.cat([x3, x4], dim=1)  # Skip connection
        x4 = self.conv7(x4)
        x4 = nn.ReLU()(x4)
        x4 = self.conv8(x4)
        x4 = nn.ReLU()(x4)

        x5 = self.up2(x4)
        x5 = torch.cat([x2, x5], dim=1)  # Skip connection
        x5 = self.conv9(x5)
        x5 = nn.ReLU()(x5)
        x5 = self.conv10(x5)
        x5 = nn.ReLU()(x5)

        x6 = self.up3(x5)
        x6 = torch.cat([x1, x6], dim=1)  # Skip connection
        x6 = self.conv11(x6)
        x6 = nn.ReLU()(x6)
        x6 = self.conv12(x6)
        x6 = nn.ReLU()(x6)

        out = self.conv13(x6)
        out = nn.Sigmoid()(out)
        return out

#数据集定义
class CustomDataset(Dataset):
    def __init__(self, image_dir, mask_dir, transform=None):
        self.image_dir = image_dir
        self.mask_dir = mask_dir
        self.transform = transform
        # 列出所有.jpg文件
        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        image_name = self.image_files[idx]
        image_path = os.path.join(self.image_dir, image_name)
        image = Image.open(image_path).convert('RGB')
        if self.transform:
            image = self.transform(image)

        # 确保掩码文件的扩展名是.png
        mask_name = os.path.splitext(image_name)[0] + '.png'
        mask_path = os.path.join(self.mask_dir, mask_name)
        mask = Image.open(mask_path).convert('L')
        if self.transform:
            mask = self.transform(mask)

        return image, mask


# 数据集准备
data_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(10),
    transforms.ColorJitter(0.1, 0.1, 0.1, 0.1),
    transforms.Resize((216, 384)),
    transforms.ToTensor(),
])

# 数据集加载
image_dir = r'/home/hubo/gather'
mask_dir = r'/home/hubo/gather1'  # 分割掩码在另一个文件夹中
dataset = CustomDataset(image_dir, mask_dir, transform=data_transform)

# 创建 DataLoader
train_loader = DataLoader(dataset, batch_size=8, shuffle=True, pin_memory=True, num_workers=4)

# 网络训练
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet(in_channels=3, out_channels=1).to(device)  # Adjust the number of channels as needed
criterion = nn.BCELoss()
optimizer = optim.AdamW(model.parameters(), lr=0.00003)

# 训练循环
for epoch in range(100):
    model.train()
    total_loss = 0.0
    num_batches = 0

    for images, ground_truth_masks in train_loader:
        images = images.to(device)
        ground_truth_masks = ground_truth_masks.to(device).float()
        masks = model(images)
        masks = masks.float()

        # 计算损失函数
        loss = criterion(masks, ground_truth_masks)

        # 反向传播和优化
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        num_batches += 1

    # 打印每个epoch的平均损失
    avg_loss = total_loss / num_batches
    print(f"Epoch [{epoch + 1}/100], Average Loss: {avg_loss:.4f}")

# 保存模型
torch.save(model.state_dict(), 'unet_weights.pth')
