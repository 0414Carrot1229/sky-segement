#把Sequential API改成函数 API之后，解决测试集代码单独运行的张量不匹配问题。
# -*- coding: utf-8 -*-
import os
import numpy as np
from PIL import Image
import tensorflow as tf
from tensorflow.keras.layers import Input, Dense, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input

# 定义图片的大小和批量大小
IMAGE_SIZE = (128, 128)  # 设置图像大小为 128x128，适应 MobileNetV2 模型
BATCH_SIZE = 16

# 定义数据文件夹路径
folder_paths = {
    'daytime': '/home/hubo/daytime',
    'night': '/home/hubo/night',
    'star': '/home/hubo/star',
    'sun_moon': '/home/hubo/sun_moon'
}

# 手动加载数据集
def load_images_from_folder(folder_path, label):
    images = []
    labels = []
    for filename in os.listdir(folder_path):
        if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):
            img_path = os.path.join(folder_path, filename)
            img = Image.open(img_path)
            img = img.resize(IMAGE_SIZE)
            img = np.array(img)
            img = preprocess_input(img)
            images.append(img)
            labels.append(label)
    return np.array(images), np.array(labels)

# 加载所有类别的图像
all_images = []
all_labels = []
for label, folder_path in folder_paths.items():
    images, labels = load_images_from_folder(folder_path, list(folder_paths.keys()).index(label))
    all_images.append(images)
    all_labels.append(labels)

# 合并所有图像和标签
all_images = np.concatenate(all_images, axis=0)
all_labels = np.concatenate(all_labels, axis=0)

# 转换标签为 one-hot 编码
all_labels = tf.keras.utils.to_categorical(all_labels, num_classes=len(folder_paths))

# 将数据集分为训练集和验证集
from sklearn.model_selection import train_test_split
train_images, val_images, train_labels, val_labels = train_test_split(all_images, all_labels, test_size=0.2, random_state=42)

# 创建训练数据集和验证数据集
train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))
train_dataset = train_dataset.shuffle(buffer_size=len(train_images)).batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)

val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))
val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(tf.data.experimental.AUTOTUNE)

# 使用 MobileNetV2 作为基础模型
base_model = MobileNetV2(
    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),  # 设置输入图像大小
    include_top=False,  # 不包括顶部的全连接层
    weights='imagenet'  # 加载预训练的权重
)
base_model.trainable = False  # 冻结基础模型的权重，不参与训练

# 构建模型，使用函数式API
inputs = Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))
x = base_model(inputs, training=False)
x = GlobalAveragePooling2D()(x)
x = Dense(512, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x)
outputs = Dense(len(folder_paths), activation='softmax')(x)

# 创建模型
model = Model(inputs, outputs)

# 编译模型
model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])

# 训练模型
history = model.fit(
    train_dataset,
    epochs=100,
    validation_data=val_dataset,  # 添加验证数据集
    verbose=1  # 打印每个 epoch 的损失
)

# 保存模型为原生的 Keras 格式
model.save('scene_recognition_model.keras')
